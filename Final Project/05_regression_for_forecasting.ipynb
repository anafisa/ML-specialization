{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование с помощью регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as ss\n",
    "from scipy import signal\n",
    "import scipy as sc\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные о количестве поездок в отобранных регионах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/regions.pkl\", \"rb\") as inf:\n",
    "    data = pickle.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21888L, 102L)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/names.pkl\", \"rb\") as inf:\n",
    "    regions = np.array(pickle.load(inf)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1075</th>\n",
       "      <th>1076</th>\n",
       "      <th>1077</th>\n",
       "      <th>1125</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "      <th>1128</th>\n",
       "      <th>1129</th>\n",
       "      <th>1130</th>\n",
       "      <th>1131</th>\n",
       "      <th>...</th>\n",
       "      <th>1630</th>\n",
       "      <th>1684</th>\n",
       "      <th>1733</th>\n",
       "      <th>1734</th>\n",
       "      <th>1783</th>\n",
       "      <th>2068</th>\n",
       "      <th>2069</th>\n",
       "      <th>2118</th>\n",
       "      <th>2119</th>\n",
       "      <th>2168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>87.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>589.0</td>\n",
       "      <td>799.0</td>\n",
       "      <td>948.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>92.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>108.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>77.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>47.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>319.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      1075   1076  1077   1125   1126   1127   1128   1129  \\\n",
       "2014-01-01 00:00:00   87.0  146.0  70.0  113.0  367.0  645.0  589.0  799.0   \n",
       "2014-01-01 01:00:00   92.0  184.0  93.0  153.0  539.0  604.0  490.0  635.0   \n",
       "2014-01-01 02:00:00  108.0  165.0  55.0  151.0  443.0  571.0  465.0  499.0   \n",
       "2014-01-01 03:00:00   77.0  108.0  32.0  112.0  372.0  533.0  442.0  370.0   \n",
       "2014-01-01 04:00:00   47.0   79.0  22.0   77.0  213.0  383.0  296.0  319.0   \n",
       "\n",
       "                      1130   1131  ...   1630  1684  1733  1734  1783  2068  \\\n",
       "2014-01-01 00:00:00  948.0  321.0  ...    9.0   0.0   5.0  89.0  10.0  35.0   \n",
       "2014-01-01 01:00:00  667.0  225.0  ...   24.0   0.0   3.0  22.0   2.0   5.0   \n",
       "2014-01-01 02:00:00  455.0  124.0  ...   27.0   0.0   3.0  23.0   1.0   1.0   \n",
       "2014-01-01 03:00:00  307.0  101.0  ...   57.0   0.0   0.0   3.0   2.0   1.0   \n",
       "2014-01-01 04:00:00  261.0   87.0  ...   38.0   0.0   1.0   9.0   1.0   8.0   \n",
       "\n",
       "                     2069   2118  2119  2168  \n",
       "2014-01-01 00:00:00   9.0  106.0  22.0  71.0  \n",
       "2014-01-01 01:00:00   0.0   87.0   0.0  44.0  \n",
       "2014-01-01 02:00:00   0.0   39.0   0.0   1.0  \n",
       "2014-01-01 03:00:00   0.0    5.0   1.0   0.0  \n",
       "2014-01-01 04:00:00   0.0   29.0   1.0  18.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('2014-01-01 00:00:00', periods=data.shape[1], freq='H')\n",
    "df = pd.DataFrame(data.transpose(), index=dates, columns=regions)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1075</th>\n",
       "      <th>1076</th>\n",
       "      <th>1077</th>\n",
       "      <th>1125</th>\n",
       "      <th>1126</th>\n",
       "      <th>1127</th>\n",
       "      <th>1128</th>\n",
       "      <th>1129</th>\n",
       "      <th>1130</th>\n",
       "      <th>1131</th>\n",
       "      <th>...</th>\n",
       "      <th>1630</th>\n",
       "      <th>1684</th>\n",
       "      <th>1733</th>\n",
       "      <th>1734</th>\n",
       "      <th>1783</th>\n",
       "      <th>2068</th>\n",
       "      <th>2069</th>\n",
       "      <th>2118</th>\n",
       "      <th>2119</th>\n",
       "      <th>2168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-03-01 00:00:00</th>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01 01:00:00</th>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01 02:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01 03:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01 04:00:00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1075  1076  1077  1125  1126   1127   1128   1129   1130  \\\n",
       "2016-03-01 00:00:00  14.0  22.0  20.0  39.0  78.0  124.0  183.0  193.0  212.0   \n",
       "2016-03-01 01:00:00  16.0  15.0  12.0  12.0  58.0   60.0   98.0  122.0  144.0   \n",
       "2016-03-01 02:00:00   4.0  14.0   0.0   9.0  23.0   55.0   59.0   93.0  162.0   \n",
       "2016-03-01 03:00:00   2.0   7.0   1.0   4.0  16.0   35.0   39.0   63.0  119.0   \n",
       "2016-03-01 04:00:00   5.0  16.0   2.0   8.0  30.0   31.0   25.0   44.0   79.0   \n",
       "\n",
       "                     1131  ...    1630  1684  1733   1734  1783  2068  2069  \\\n",
       "2016-03-01 00:00:00  31.0  ...     4.0   0.0   1.0  105.0  16.0  59.0  20.0   \n",
       "2016-03-01 01:00:00  14.0  ...     5.0   0.0   2.0    5.0   1.0  33.0   9.0   \n",
       "2016-03-01 02:00:00  21.0  ...    10.0   1.0   0.0    0.0   0.0   1.0   0.0   \n",
       "2016-03-01 03:00:00  11.0  ...    10.0   0.0   0.0    0.0   0.0   0.0   0.0   \n",
       "2016-03-01 04:00:00   4.0  ...     7.0   0.0   0.0    4.0   1.0   0.0   0.0   \n",
       "\n",
       "                      2118  2119   2168  \n",
       "2016-03-01 00:00:00  146.0  12.0  120.0  \n",
       "2016-03-01 01:00:00   71.0   6.0   23.0  \n",
       "2016-03-01 02:00:00   18.0   0.0    0.0  \n",
       "2016-03-01 03:00:00   11.0   0.0    1.0  \n",
       "2016-03-01 04:00:00   34.0   0.0    1.0  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = df.loc['2016-03-01 00:00:00':'2016-05-31 17:00:00']\n",
    "df_s_f = df.loc['2016-03-01 00:00:00':'2016-05-31 23:00:00']\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для моделирования сезонностей и создания dummy переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fourier_regressors(data_f, num_end):\n",
    "    str_var = ''\n",
    "    length = data_f.shape[0]\n",
    "    for i in range(1, num_end+1):\n",
    "        sin = \"s_\" + str(i)\n",
    "        cos = \"c_\" + str(i)\n",
    "        data_f[sin] = np.sin(2*np.pi*i*np.arange(1, length+1)/168.0)\n",
    "        data_f[cos] = np.cos(2*np.pi*i*np.arange(1, length+1)/168.0)\n",
    "        str_var = str_var + sin + ' + '\n",
    "        if i != num_end:\n",
    "            str_var = str_var + cos + ' + '\n",
    "        else:\n",
    "            str_var = str_var + cos\n",
    "    return str_var\n",
    "\n",
    "def make_dummy_weekday(data):\n",
    "    data['monday'] = [1 if date.weekday() == 0 else 0 for date in data.index]\n",
    "    data['tuesday'] = [1 if date.weekday() == 1 else 0 for date in data.index]\n",
    "    data['wednessday'] = [1 if date.weekday() == 2 else 0 for date in data.index]\n",
    "    data['thursday'] = [1 if date.weekday() == 3 else 0 for date in data.index]\n",
    "    data['friday'] = [1 if date.weekday() == 4 else 0 for date in data.index]\n",
    "    data['saturday'] = [1 if date.weekday() == 5 else 0 for date in data.index]\n",
    "    data['sunday'] = [1 if date.weekday() == 6 else 0 for date in data.index]\n",
    "    weekday_str = ' + tuesday + wednessday + thursday + friday + saturday + sunday'\n",
    "    return weekday_str\n",
    "\n",
    "def fourier_prediction(data, train_time_limit, degree=49):\n",
    "    data_c = pd.DataFrame(data.values, columns = ['val'], index = data.index)\n",
    "    str_reg = 'val ~ '\n",
    "    week_day_str, str_var = '', ''\n",
    "    str_var = make_fourier_regressors(data_c, degree)\n",
    "    week_day_str = make_dummy_weekday(data_c)\n",
    "    model = smf.ols(str_reg + str_var + week_day_str, data=data_c.loc[:train_time_limit])\n",
    "    fitted = model.fit(cov_type='HC1')\n",
    "    return fitted.predict(data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_construction(data, data_f, train_time_limit):\n",
    "   \n",
    "    K = 12 # number of hour lags\n",
    "    K_d = 7 # number of daily lags\n",
    "    K_f = 49 # number of fourier components\n",
    "\n",
    "    # data construction\n",
    "    offset = K_d*24\n",
    "    train_num_limit = []\n",
    "    test_num_start = data.loc[:train_time_limit].shape[0] - 1\n",
    "    df_res = []\n",
    "    for data_num in range(1, 7):\n",
    "        train_num_limit.append(data.loc[:train_time_limit].shape[0] - data_num)\n",
    "    length = data.shape[0]\n",
    "    for column in data.columns:\n",
    "        train_df_list = []\n",
    "        for data_num in range(6):\n",
    "            train_df_list.append(pd.DataFrame())\n",
    "        test_df = pd.DataFrame()\n",
    "        test_fourier = pd.DataFrame()\n",
    "       \n",
    "        for col in data.columns:\n",
    "            for data_num in range(6):\n",
    "                if col == column:\n",
    "                    train_df_list[data_num]['region'+str(col)] = [1]*(train_num_limit[data_num] - offset)\n",
    "                else:\n",
    "                    train_df_list[data_num]['region'+str(col)] = [0]*(train_num_limit[data_num] - offset)\n",
    "            if col == column:\n",
    "                test_df['region'+str(col)] = [1]*(length - test_num_start)\n",
    "            else:\n",
    "                test_df['region'+str(col)] = [0]*(length - test_num_start)\n",
    "        \n",
    "        for data_num in range(6):\n",
    "            train_df_list[data_num]['region'] = [column]*(train_num_limit[data_num] - offset)\n",
    "        test_df['region'] = [column]*(length - test_num_start)\n",
    "       \n",
    "        for h in range(24):\n",
    "            for data_num in range(6):\n",
    "                train_df_list[data_num]['hour_'+str(h)] = \\\n",
    "                        map(lambda x: 1 if x.hour == h else 0, data.iloc[offset:train_num_limit[data_num]].index)\n",
    "            test_df['hour_'+str(h)] = map(lambda x: 1 if x.hour == h else 0, data.iloc[test_num_start:].index)\n",
    "        \n",
    "        # Day\n",
    "        for h in range(7):\n",
    "            for data_num in range(6):\n",
    "                train_df_list[data_num]['day_'+str(h)] = \\\n",
    "                        map(lambda x: 1 if x.weekday() == h else 0, data.iloc[offset:train_num_limit[data_num]].index)\n",
    "            test_df['day_'+str(h)] = map(lambda x: 1 if x.weekday() == h else 0, data.iloc[test_num_start:].index)\n",
    "        # Value\n",
    "        for data_num in range(6):\n",
    "            train_df_list[data_num]['val'] = data.iloc[offset:train_num_limit[data_num]][column].values\n",
    "        test_df['val'] = data.iloc[test_num_start:][column].values\n",
    "        for ind in range(1, K+1):\n",
    "            for data_num in range(6):\n",
    "                train_df_list[data_num]['val_'+str(ind)] = \\\n",
    "                        data.iloc[offset-ind:train_num_limit[data_num]-ind][column].values\n",
    "            test_df['val_'+str(ind)] = data.iloc[test_num_start-ind:-ind][column].values\n",
    "        for ind in range(1, K_d+1):\n",
    "            for data_num in range(6):\n",
    "                train_df_list[data_num]['val_d_'+str(ind)] = \\\n",
    "                        data.iloc[offset-24*ind:train_num_limit[data_num]-24*ind][column].values\n",
    "            test_df['val_d_'+str(ind)] = data.iloc[test_num_start-24*ind:-24*ind][column].values\n",
    "            \n",
    "        # Fourier components\n",
    "        fourier_pred = fourier_prediction(df_s_f[column], '2016-04-30 23:00:00', 49)\n",
    "        for data_num in range(6):\n",
    "            (train_df_list[data_num])['fourier'] = fourier_pred[offset + data_num + 1:test_num_start+1].values\n",
    "            test_fourier['f'+str(data_num)] = fourier_pred[test_num_start + data_num:-6+data_num].values\n",
    "        test_df['fourier'] = [0]*(test_df.shape[0])\n",
    "        \n",
    "        # Target values\n",
    "        for data_num in range(6):\n",
    "            train_df_list[data_num]['target'] = data.iloc[offset + data_num + 1:test_num_start+1][column].values\n",
    "        # Info for submission\n",
    "        test_df['sub_info'] = df_s.iloc[test_num_start:].index\n",
    "        # Stacking data\n",
    "        if column == 1075:\n",
    "            df_res = train_df_list\n",
    "            df_test = test_df\n",
    "            df_test_f = test_fourier\n",
    "        else:\n",
    "            for data_num in range(6):\n",
    "                df_res[data_num] = pd.concat((df_res[data_num], train_df_list[data_num]), axis=0)\n",
    "            df_test = pd.concat((df_test, test_df), axis=0)\n",
    "            df_test_f = pd.concat((df_test_f, test_fourier), axis=0)\n",
    "    for data_num in range(6):\n",
    "        df_res[data_num].index = range(df_res[data_num].shape[0])\n",
    "    df_test.index = range(df_test.shape[0])\n",
    "    df_test_f.index = range(df_test_f.shape[0])\n",
    "    return df_res, df_test, df_test_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучаться на данных с марта 2016 года."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df.loc['2016-03-01 00:00:00':'2016-05-31 17:00:00']\n",
    "df_s_f = df.loc['2016-03-01 00:00:00':'2016-05-31 23:00:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построение данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "res, test, test_f = data_construction(df_s, df_s_f, '2016-04-30 23:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Обучение моделей. В качестве регрессионной модели будем использовать ElasticNet. Подберем параметры моделей: alpha и l1_ratio. Первый обозначает множителей регуляризационных членов, а второй - пропорцию между l1 и l2 регуляризаторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем оптимальные параметры для каждой регрессионной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bst_params(data_num):\n",
    "    R, H = 102, 739\n",
    "    denom = 1.0/(R*H*6)\n",
    "    alpha_list = np.arange(0.1,1.1,0.2)\n",
    "    l1_ratio = np.arange(0.1,1.1,0.2)\n",
    "    bst_score = np.inf\n",
    "    for alpha in alpha_list:\n",
    "        for ratio in l1_ratio:\n",
    "            regressor = ElasticNet(alpha=alpha, l1_ratio=ratio)\n",
    "            regressor.fit(res[data_num].iloc[:,:-1], res[data_num].target)\n",
    "            test['fourier'] = test_f['f'+str(data_num)]\n",
    "            prediction = regressor.predict(test.drop(['sub_info'], axis=1))\n",
    "            difference = denom*np.abs(prediction - \\\n",
    "                                        df.loc['2016-05-01 0'+str(0+data_num)+':00:00':'2016-05-31 '\\\n",
    "                                               +str(18+data_num)+':00:00'].values.ravel(order='F'))\n",
    "            err = difference.sum()\n",
    "            if err < bst_score:\n",
    "                bst_params = (alpha, ratio)\n",
    "                bst_score = err\n",
    "    return bst_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "for data_num in range(6):\n",
    "    params_list.append(find_bst_params(data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/params.pkl\", 'wb') as inf:\n",
    "    pickle.dump(params_list, inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Набор оптимальных параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.10000000000000001, 0.50000000000000011),\n",
       " (0.10000000000000001, 0.10000000000000001),\n",
       " (0.10000000000000001, 0.10000000000000001),\n",
       " (0.90000000000000013, 0.90000000000000013),\n",
       " (0.30000000000000004, 0.50000000000000011),\n",
       " (0.30000000000000004, 0.50000000000000011)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модели с оптимальными параметрами на данных до апреля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Models training\n",
    "regressors_list = []\n",
    "for data_num in range(6):\n",
    "    regressor = ElasticNet(alpha=params_list[data_num][0], l1_ratio=params_list[data_num][1])\n",
    "    regressor.fit(res[data_num].iloc[:,:-1], res[data_num].target)\n",
    "    regressors_list.append(regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания на май 2016 года и считаем ошибку предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 878 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# May predictions\n",
    "R = 102\n",
    "H = 739\n",
    "Q_may = 0\n",
    "denom = 1.0/(R*H*6)\n",
    "for data_num in range(6):\n",
    "    test['fourier'] = test_f['f'+str(data_num)]\n",
    "    prediction = regressors_list[data_num].predict(test.drop(['sub_info'], axis=1))\n",
    "    difference = denom*np.abs(prediction - \\\n",
    "                        df.loc['2016-05-01 0'+str(0+data_num)+':00:00':'2016-05-31 '\\\n",
    "                               +str(18+data_num)+':00:00'].values.ravel(order='F'))\n",
    "    Q_may += difference.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.629759364887121"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_may"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем соответствующие данные и создаекм выборки для обучения и тестирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_s = df.loc['2016-03-01 00:00:00':'2016-06-30 17:00:00']\n",
    "df_s_f = df.loc['2016-03-01 00:00:00':'2016-06-30 23:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 42.2 s, total: 3min 27s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res, test, test_f = data_construction(df_s, df_s_f, '2016-05-31 23:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем регрессионные модели модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min, sys: 38.2 s, total: 4min 39s\n",
      "Wall time: 2min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Models training\n",
    "regressors_list = []\n",
    "for data_num in range(6):\n",
    "    regressor = ElasticNet(alpha=params_list[data_num][0], l1_ratio=params_list[data_num][1])\n",
    "    regressor.fit(res[data_num].iloc[:,:-1], res[data_num].target)\n",
    "    regressors_list.append(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_ids = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формат данных для отправки результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1075_2016-05-31_23_1\n",
       "1     1075_2016-06-01_0_1\n",
       "2     1075_2016-06-01_1_1\n",
       "3     1075_2016-06-01_2_1\n",
       "4     1075_2016-06-01_3_1\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.region.apply(str) + '_' + test.sub_info.apply(lambda x: x.strftime('%Y-%m-%d')) + '_' + \\\n",
    "                   test.sub_info.apply(lambda x: str(x.hour)) + '_' + str(0+1)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания для июня."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 13.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R = 102\n",
    "H = 715\n",
    "Q_june = 0\n",
    "denom = 1.0/(R*H*6)\n",
    "for data_num in range(6):\n",
    "    test['fourier'] = test_f['f'+str(data_num)]\n",
    "    prediction = regressors_list[data_num].predict(test.drop(['sub_info'], axis=1))\n",
    "    difference = denom*np.abs(prediction - \\\n",
    "                        df.loc['2016-06-01 0'+str(0+data_num)+':00:00':'2016-06-30 '\\\n",
    "                               +str(18+data_num)+':00:00'].values.ravel(order='F'))\n",
    "    all_predictions.append(prediction)\n",
    "    all_ids.append(test.region.apply(str) + '_' + test.sub_info.apply(lambda x: x.strftime('%Y-%m-%d')) + '_' + \\\n",
    "                   test.sub_info.apply(lambda x: str(x.hour)) + '_' + str(data_num+1))\n",
    "    Q_june += difference.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.3109876884\n"
     ]
    }
   ],
   "source": [
    "print Q_june"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_num in range(6):\n",
    "    if data_num == 0:\n",
    "        pred_df = pd.DataFrame(all_predictions[data_num], index=all_ids[data_num], columns=['y'])\n",
    "    else:\n",
    "        pred_df = pd.concat((pred_df, pd.DataFrame(all_predictions[data_num], index=all_ids[data_num], columns=['y'])),\\\n",
    "                            axis = 0)\n",
    "pred_df.index.name = 'id'\n",
    "pred_df.to_csv(\"submission.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R = 102\n",
    "H = 739\n",
    "Q_may = 0\n",
    "denom = 1.0/(R*H*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_error_region(data, train_time_limit, test_time_limit, region, denom, pred_start='2016-05-01', pred_end='2016-05-31', degree=49,\n",
    "                       K_d=2, K_h=8):\n",
    "    new_data = pd.DataFrame(data.loc[:test_time_limit][region].values, columns=['val'], \\\n",
    "                            index = data.loc[:test_time_limit].index)\n",
    "    error = 0\n",
    "    all_ids = []\n",
    "    all_preds = []\n",
    "    offset = max(24*K_d, K_h, 12)\n",
    "    # 12-hours \n",
    "    new_data['half_day_sum'] = new_data['val'].rolling(12).sum().fillna(0)\n",
    "    # fourier components\n",
    "    str_var = make_fourier_regressors(new_data, degree)\n",
    "    # weekday dummy components\n",
    "    week_day_str = make_dummy_weekday(new_data)\n",
    "    # day lags\n",
    "    for day_lag in range(1, K_d):\n",
    "        new_data['day_lag_'+str(day_lag)] = [0]*offset + new_data[offset-24*day_lag:-24*day_lag]['val'].values.tolist()\n",
    "    # hour lags\n",
    "    for hour_lag in range(1, K_h):\n",
    "        new_data['hour_lag_'+str(hour_lag)] = [0]*offset + new_data[offset-hour_lag:-hour_lag]['val'].values.tolist()\n",
    "    # Training and predictions\n",
    "    for data_num in range(6):\n",
    "        train_num_limit = data.loc[:train_time_limit].shape[0] - data_num\n",
    "        regressor = ElasticNet(alpha=0.1, l1_ratio=0.6)\n",
    "        regressor.fit(new_data.iloc[offset:train_num_limit].drop(['val'], axis=1), \\\n",
    "                      new_data.iloc[offset+data_num+1:train_num_limit+data_num+1].val)\n",
    "        prediction = regressor.predict(new_data[train_time_limit:].drop(['val'], axis=1))\n",
    "        difference = denom*np.abs(prediction - \\\n",
    "                        data.loc[pred_start+' 0'+str(0+data_num)+':00:00':pred_end+' '\\\n",
    "                               +str(18+data_num)+':00:00'][region].values)\n",
    "        error += difference.sum()\n",
    "        \n",
    "        indexes = new_data[train_time_limit:].index    \n",
    "        all_ids.append((pd.Series([str(region)]*indexes.size) + '_' + map(lambda x: x.strftime('%Y-%m-%d'), indexes) + '_' \\\n",
    "                           + map(lambda x: str(x.hour) + '_' + str(data_num+1), indexes)).values)\n",
    "        all_preds.append(prediction)\n",
    "    del new_data\n",
    "    return error, all_preds, all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание для одного из регионов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115087256071\n",
      "Wall time: 6.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "err, _, _ = count_error_region(df.loc[:'2016-05-31 23:00:00'], '2016-04-30 23:00:00', '2016-05-31 17:00:00', 1075, denom)\n",
    "print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания для мая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20.9557200193\n",
      "CPU times: user 18min 28s, sys: 3min 13s, total: 21min 42s\n",
      "Wall time: 12min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Q_may = 0\n",
    "for region in df.columns:\n",
    "    res, pred, ids = count_error_region(df.loc[:'2016-05-31 23:00:00'], \\\n",
    "                                        '2016-04-30 23:00:00', '2016-05-31 17:00:00', region, denom)\n",
    "    Q_may += res\n",
    "print(\"\\n\", Q_may)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка предсказания на май 2016 года. Она значительно уменьшилась по сравнению с прошлой неделей: было около 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.9557200193\n"
     ]
    }
   ],
   "source": [
    "print(Q_may)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказания на июнь по данным до мая 2016 года и считаем ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3926429294\n",
      "CPU times: user 19min 13s, sys: 2min 24s, total: 21min 37s\n",
      "Wall time: 11min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "R = 102\n",
    "H = 715\n",
    "denom = 1.0/(R*H*6)\n",
    "Q_june = 0\n",
    "all_ids = []\n",
    "all_preds = []\n",
    "for region in df.columns:\n",
    "    res, pred, ids = count_error_region(df.loc[:'2016-06-30 23:00:00'], \\\n",
    "                                        '2016-05-31 23:00:00', '2016-06-30 17:00:00', \n",
    "                                        region, denom,\n",
    "                                        '2016-06-01', '2016-06-30')\n",
    "    Q_june += res\n",
    "    all_ids.append(ids)\n",
    "    all_preds.append(pred)\n",
    "print(Q_june)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.array(all_preds).ravel(), index=np.array(all_ids).ravel(), columns=['y'])\n",
    "pred_df.index.name = 'id'\n",
    "pred_df.to_csv(\"result.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(437580, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
