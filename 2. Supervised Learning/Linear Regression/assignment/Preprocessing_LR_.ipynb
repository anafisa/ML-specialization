{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных и логистическая регрессия для задачи бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании вам будет предложено ознакомиться с основными техниками предобработки данных, а так же применить их для обучения модели логистической регрессии. Ответ потребуется загрузить в соответствующую форму в виде 6 текстовых файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "from sklearn import model_selection, linear_model, metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: по 38 признакам, связанных с заявкой на грант (область исследований учёных, информация по их академическому бэкграунду, размер гранта, область, в которой он выдаётся) предсказать, будет ли заявка принята. Датасет включает в себя информацию по 6000 заявкам на гранты, которые были поданы в университете Мельбурна в период с 2004 по 2008 год.\n",
    "\n",
    "Полную версию данных с большим количеством признаков можно найти на https://www.kaggle.com/c/unimelb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим из датасета целевую переменную Grant.Status и обозначим её за y\n",
    "Теперь X обозначает обучающую выборку, y - ответы на ней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Grant.Status', 1)\n",
    "y = data['Grant.Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теория по логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После осознания того, какую именно задачу требуется решить на этих данных, следующим шагом при реальном анализе был бы подбор подходящего метода. В данном задании выбор метода было произведён за вас, это логистическая регрессия. Кратко напомним вам используемую модель.\n",
    "\n",
    "Логистическая регрессия предсказывает вероятности принадлежности объекта к каждому классу. Сумма ответов логистической регрессии на одном объекте для всех классов равна единице.\n",
    "\n",
    "$$ \\sum_{k=1}^K \\pi_{ik} = 1, \\quad \\pi_k \\equiv P\\,(y_i = k \\mid x_i, \\theta), $$\n",
    "\n",
    "где:\n",
    "- $\\pi_{ik}$ - вероятность принадлежности объекта $x_i$ из выборки $X$ к классу $k$\n",
    "- $\\theta$ - внутренние параметры алгоритма, которые настраиваются в процессе обучения, в случае логистической регрессии - $w, b$\n",
    "\n",
    "Из этого свойства модели в случае бинарной классификации требуется вычислить лишь вероятность принадлежности объекта к одному из классов (вторая вычисляется из условия нормировки вероятностей). Эта вероятность вычисляется, используя логистическую функцию:\n",
    "\n",
    "$$ P\\,(y_i = 1 \\mid x_i, \\theta) = \\frac{1}{1 + \\exp(-w^T x_i-b)} $$\n",
    "\n",
    "Параметры $w$ и $b$ находятся, как решения следующей задачи оптимизации (указаны функционалы с L1 и L2 регуляризацией, с которыми вы познакомились в предыдущих заданиях):\n",
    "\n",
    "L2-regularization:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\frac{1}{2} w^T w + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "L1-regularization:\n",
    "\n",
    "$$ Q(X, y, \\theta) = \\sum_{d=1}^D |w_d| + C \\sum_{i=1}^l \\log ( 1 + \\exp(-y_i (w^T x_i + b ) ) ) \\longrightarrow \\min\\limits_{w,b} $$\n",
    "\n",
    "$C$ - это стандартный гиперпараметр модели, который регулирует то, насколько сильно мы позволяем модели подстраиваться под данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из свойств данной модели следует, что:\n",
    "- все $X$ должны быть числовыми данными (в случае наличия среди них категорий, их требуется некоторым способом преобразовать в вещественные числа)\n",
    "- среди $X$ не должно быть пропущенных значений (т.е. все пропущенные значения перед применением модели следует каким-то образом заполнить)\n",
    "\n",
    "Поэтому базовым этапом в предобработке любого датасета для логистической регрессии будет кодирование категориальных признаков, а так же удаление или интерпретация пропущенных значений (при наличии того или другого)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Sponsor.Code</th>\n",
       "      <th>Grant.Category.Code</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>RFCD.Percentage.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept.No..1</th>\n",
       "      <th>Faculty.No..1</th>\n",
       "      <th>With.PHD.1</th>\n",
       "      <th>No..of.Years.in.Uni.at.Time.of.Grant.1</th>\n",
       "      <th>Number.of.Successful.Grant.1</th>\n",
       "      <th>Number.of.Unsuccessful.Grant.1</th>\n",
       "      <th>A..1</th>\n",
       "      <th>A.1</th>\n",
       "      <th>B.1</th>\n",
       "      <th>C.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21A</td>\n",
       "      <td>50A</td>\n",
       "      <td>A</td>\n",
       "      <td>230202.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>230203.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>230204.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3098.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;=0 to 5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4D</td>\n",
       "      <td>10A</td>\n",
       "      <td>D</td>\n",
       "      <td>320801.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;=0 to 5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>321004.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>321015.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2813.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than 0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>51C</td>\n",
       "      <td>20C</td>\n",
       "      <td>A</td>\n",
       "      <td>291503.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>321402.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more than 15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>24D</td>\n",
       "      <td>30B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380107.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than 0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status Sponsor.Code Grant.Category.Code  \\\n",
       "0             1          21A                 50A   \n",
       "1             1           4D                 10A   \n",
       "2             0          NaN                 NaN   \n",
       "3             0          51C                 20C   \n",
       "4             0          24D                 30B   \n",
       "\n",
       "  Contract.Value.Band...see.note.A  RFCD.Code.1  RFCD.Percentage.1  \\\n",
       "0                               A      230202.0               50.0   \n",
       "1                               D      320801.0              100.0   \n",
       "2                              NaN     320602.0               50.0   \n",
       "3                               A      291503.0               60.0   \n",
       "4                              NaN     380107.0              100.0   \n",
       "\n",
       "   RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3  RFCD.Percentage.3  ...  \\\n",
       "0     230203.0               30.0     230204.0               20.0  ...   \n",
       "1          0.0                0.0          0.0                0.0  ...   \n",
       "2     321004.0               30.0     321015.0               20.0  ...   \n",
       "3     321402.0               40.0          0.0                0.0  ...   \n",
       "4          0.0                0.0          0.0                0.0  ...   \n",
       "\n",
       "   Dept.No..1  Faculty.No..1  With.PHD.1  \\\n",
       "0      3098.0           31.0        Yes    \n",
       "1      2553.0           25.0        Yes    \n",
       "2      2813.0           25.0         NaN   \n",
       "3      2553.0           25.0         NaN   \n",
       "4      2923.0           25.0         NaN   \n",
       "\n",
       "   No..of.Years.in.Uni.at.Time.of.Grant.1  Number.of.Successful.Grant.1  \\\n",
       "0                                >=0 to 5                           2.0   \n",
       "1                                >=0 to 5                           3.0   \n",
       "2                             Less than 0                           1.0   \n",
       "3                            more than 15                           2.0   \n",
       "4                             Less than 0                           0.0   \n",
       "\n",
       "   Number.of.Unsuccessful.Grant.1  A..1  A.1  B.1  C.1  \n",
       "0                             0.0   0.0  4.0  2.0  0.0  \n",
       "1                             1.0   0.0  2.0  0.0  0.0  \n",
       "2                             5.0   0.0  7.0  2.0  0.0  \n",
       "3                             1.0   5.0  6.0  9.0  1.0  \n",
       "4                             2.0   0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в датасете есть как числовые, так и категориальные признаки. Получим списки их названий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['RFCD.Percentage.1', 'RFCD.Percentage.2', 'RFCD.Percentage.3', \n",
    "                'RFCD.Percentage.4', 'RFCD.Percentage.5',\n",
    "                'SEO.Percentage.1', 'SEO.Percentage.2', 'SEO.Percentage.3',\n",
    "                'SEO.Percentage.4', 'SEO.Percentage.5',\n",
    "                'Year.of.Birth.1', 'Number.of.Successful.Grant.1', 'Number.of.Unsuccessful.Grant.1']\n",
    "categorical_cols = list(set(X.columns.values.tolist()) - set(numeric_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в нём присутствуют пропущенные значения. Очевидны решением будет исключение всех данных, у которых пропущено хотя бы одно значение. Сделаем это:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что тогда мы выбросим почти все данные, и такой метод решения в данном случае не сработает.\n",
    "\n",
    "Пропущенные значения можно так же интерпретировать, для этого существует несколько способов, они различаются для категориальных и вещественных признаков.\n",
    "\n",
    "Для вещественных признаков:\n",
    "- заменить на 0 (данный признак давать вклад в предсказание для данного объекта не будет)\n",
    "- заменить на среднее (каждый пропущенный признак будет давать такой же вклад, как и среднее значение признака на датасете)\n",
    "\n",
    "Для категориальных:\n",
    "- интерпретировать пропущенное значение, как ещё одну категорию (данный способ является самым естественным, так как в случае категорий у нас есть уникальная возможность не потерять информацию о наличии пропущенных значений; обратите внимание, что в случае вещественных признаков данная информация неизбежно теряется)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Задание 0. Обработка пропущенных значений.\n",
    "1. Заполните пропущенные вещественные значения в X нулями и средними по столбцам, назовите полученные датафреймы X_real_zeros и X_real_mean соответственно. Для подсчёта средних используйте описанную ниже функцию calculate_means, которой требуется передать на вход вешественные признаки из исходного датафрейма. **Для подсчета среднего можно использовать функцию pandas.mean()**\n",
    "2. Все категориальные признаки в X преобразуйте в строки, пропущенные значения требуется также преобразовать в какие-либо строки, которые не являются категориями (например, 'NA'), полученный датафрейм назовите X_cat.\n",
    "\n",
    "Для объединения выборок здесь и далее в задании рекомендуется использовать функции\n",
    "\n",
    "    np.hstack(...)\n",
    "    np.vstack(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_means(numeric_data):\n",
    "    means = np.zeros(numeric_data.shape[1])\n",
    "    for j in range(numeric_data.shape[1]):\n",
    "        to_sum = numeric_data.iloc[:,j]\n",
    "        indices = np.nonzero(~numeric_data.iloc[:,j].isnull())[0]\n",
    "        correction = np.amax(to_sum[indices])\n",
    "        to_sum /= correction\n",
    "        for i in indices:\n",
    "            means[j] += to_sum[i]\n",
    "        means[j] /= indices.size\n",
    "        means[j] *= correction\n",
    "    return pd.Series(means, numeric_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real = X[numeric_cols]\n",
    "X_real_zeros = X_real.fillna(0)\n",
    "X_real_mean = X_real.fillna(calculate_means(X_real.copy()))\n",
    "X_cat = X[categorical_cols].fillna(\"NA\").astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование категориальных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущей ячейке мы разделили наш датасет ещё на две части: в одной присутствуют только вещественные признаки, в другой только категориальные. Это понадобится нам для раздельной последующей обработке этих данных, а так же для сравнения качества работы тех или иных методов.\n",
    "\n",
    "Для использования модели регрессии требуется преобразовать категориальные признаки в вещественные. Рассмотрим основной способ преоборазования категориальных признаков в вещественные: one-hot encoding. Его идея заключается в том, что мы преобразуем категориальный признак при помощи бинарного кода: каждой категории ставим в соответствие набор из нулей и единиц.\n",
    "\n",
    "Посмотрим, как данный метод работает на простом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходные данные:\n",
      "\n",
      "      sex nationality\n",
      "0    male    American\n",
      "1  female    European\n",
      "2    male       Asian\n",
      "3  female    European\n",
      "\n",
      "Закодированные данные:\n",
      "\n",
      "[[1. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "categorial_data = pd.DataFrame({'sex': ['male', 'female', 'male', 'female'], \n",
    "                                'nationality': ['American', 'European', 'Asian', 'European']})\n",
    "print('Исходные данные:\\n')\n",
    "print(categorial_data)\n",
    "encoder = DV(sparse = False)\n",
    "encoded_data = encoder.fit_transform(categorial_data.T.to_dict().values())\n",
    "print('\\nЗакодированные данные:\\n')\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в первые три колонки оказалась закодированна информация о стране, а во вторые две - о поле. При этом для совпадающих элементов выборки строки будут полностью совпадать. Также из примера видно, что кодирование признаков сильно увеличивает их количество, но полностью сохраняет информацию, в том числе о наличии пропущенных значений (их наличие просто становится одним из бинарных признаков в преобразованных данных).\n",
    "\n",
    "Теперь применим one-hot encoding к категориальным признакам из исходного датасета. Обратите внимание на общий для всех методов преобработки данных интерфейс. Функция\n",
    "\n",
    "    encoder.fit_transform(X)\n",
    "    \n",
    "позволяет вычислить необходимые параметры преобразования, впоследствии к новым данным можно уже применять функцию\n",
    "\n",
    "    encoder.transform(X)\n",
    "    \n",
    "Очень важно применять одинаковое преобразование как к обучающим, так и тестовым данным, потому что в противном случае вы получите непредсказуемые, и, скорее всего, плохие результаты. В частности, если вы отдельно закодируете обучающую и тестовую выборку, то получите вообще говоря разные коды для одних и тех же признаков, и ваше решение работать не будет.\n",
    "\n",
    "Также параметры многих преобразований (например, рассмотренное ниже масштабирование) нельзя вычислять одновременно на данных из обучения и теста, потому что иначе подсчитанные на тесте метрики качества будут давать смещённые оценки на качество работы алгоритма. Кодирование категориальных признаков не считает на обучающей выборке никаких параметров, поэтому его можно применять сразу к всему датасету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = DV(sparse = False)\n",
    "X_cat_oh = encoder.fit_transform(X_cat.T.to_dict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для построения метрики качества по результату обучения требуется разделить исходный датасет на обучающую и тестовую выборки.\n",
    "\n",
    "Обращаем внимание на заданный параметр для генератора случайных чисел: random_state. Так как результаты на обучении и тесте будут зависеть от того, как именно вы разделите объекты, то предлагается использовать заранее определённое значение для получение результатов, согласованных с ответами в системе проверки заданий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(X_train_real_zeros, \n",
    " X_test_real_zeros, \n",
    " y_train, y_test) = train_test_split(X_real_zeros, y, \n",
    "                                     test_size=0.3, \n",
    "                                     random_state=0)\n",
    "(X_train_real_mean, \n",
    " X_test_real_mean) = train_test_split(X_real_mean, \n",
    "                                      test_size=0.3, \n",
    "                                      random_state=0)\n",
    "(X_train_cat_oh,\n",
    " X_test_cat_oh) = train_test_split(X_cat_oh, \n",
    "                                   test_size=0.3, \n",
    "                                   random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы получили первые наборы данных, для которых выполнены оба ограничения логистической регрессии на входные данные. Обучим на них регрессию, используя имеющийся в библиотеке sklearn функционал по подбору гиперпараметров модели\n",
    "    \n",
    "    optimizer = GridSearchCV(estimator, param_grid)\n",
    "\n",
    "где:\n",
    "- estimator - обучающий алгоритм, для которого будет производиться подбор параметров\n",
    "- param_grid - словарь параметров, ключами которого являются строки-названия, которые передаются алгоритму estimator, а значения - набор параметров для перебора\n",
    "\n",
    "Данный класс выполняет кросс-валидацию обучающей выборки для каждого набора параметров и находит те, на которых алгоритм работает лучше всего. Этот метод позволяет настраивать гиперпараметры по обучающей выборке, избегая переобучения. Некоторые опциональные параметры вызова данного класса, которые нам понадобятся:\n",
    "- scoring - функционал качества, максимум которого ищется кросс валидацией, по умолчанию используется функция score() класса esimator\n",
    "- n_jobs - позволяет ускорить кросс-валидацию, выполняя её параллельно, число определяет количество одновременно запущенных задач\n",
    "- cv - количество фолдов, на которые разбивается выборка при кросс-валидации\n",
    "\n",
    "После инициализации класса GridSearchCV, процесс подбора параметров запускается следующим методом:\n",
    "\n",
    "    optimizer.fit(X, y)\n",
    "    \n",
    "На выходе для получения предсказаний можно пользоваться функцией\n",
    "\n",
    "    optimizer.predict(X)\n",
    "    \n",
    "для меток или\n",
    "\n",
    "    optimizer.predict_proba(X)\n",
    "    \n",
    "для вероятностей (в случае использования логистической регрессии).\n",
    "    \n",
    "Также можно напрямую получить оптимальный класс estimator и оптимальные параметры, так как они является атрибутами класса GridSearchCV:\n",
    "- best\\_estimator\\_ - лучший алгоритм\n",
    "- best\\_params\\_ - лучший набор параметров\n",
    "\n",
    "Класс логистической регрессии выглядит следующим образом:\n",
    "\n",
    "    estimator = LogisticRegression(penalty)\n",
    "   \n",
    "где penalty принимает либо значение 'l2', либо 'l1'. По умолчанию устанавливается значение 'l2', и везде в задании, если об этом не оговорено особо, предполагается использование логистической регрессии с L2-регуляризацией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Сравнение способов заполнения вещественных пропущенных значений.\n",
    "1. Составьте две обучающие выборки из вещественных и категориальных признаков: в одной вещественные признаки, где пропущенные значения заполнены нулями, в другой - средними. Рекомендуется записывать в выборки сначала вещественные, а потом категориальные признаки.\n",
    "2. Обучите на них логистическую регрессию, подбирая параметры из заданной сетки param_grid по методу кросс-валидации с числом фолдов cv=3. В качестве оптимизируемой функции используйте заданную по умолчанию.\n",
    "3. Постройте два графика оценок точности +- их стандратного отклонения в зависимости от гиперпараметра и убедитесь, что вы действительно нашли её максимум. Также обратите внимание на большую дисперсию получаемых оценок (уменьшить её можно увеличением числа фолдов cv).\n",
    "4. Получите две метрики качества AUC ROC на тестовой выборке и сравните их между собой. Какой способ заполнения пропущенных вещественных значений работает лучше? В дальнейшем для выполнения задания в качестве вещественных признаков используйте ту выборку, которая даёт лучшее качество на тесте.\n",
    "5. Передайте два значения AUC ROC (сначала для выборки, заполненной средними, потом для выборки, заполненной нулями) в функцию write_answer_1 и запустите её. Полученный файл является ответом на 1 задание.\n",
    "\n",
    "Информация для интересующихся: вообще говоря, не вполне логично оптимизировать на кросс-валидации заданный по умолчанию в классе логистической регрессии функционал accuracy, а измерять на тесте AUC ROC, но это, как и ограничение размера выборки, сделано для ускорения работы процесса кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def plot_scores(optimizer):\n",
    "    scores=[]\n",
    "    for i in range(len(optimizer.cv_results_['params'])):\n",
    "        scores.append([optimizer.cv_results_['params'][i]['C'], \n",
    "                optimizer.cv_results_['mean_test_score'][i],\n",
    "                optimizer.cv_results_['std_test_score'][i]])\n",
    "    scores = np.array(scores)\n",
    "    plt.semilogx(scores[:,0], scores[:,1])\n",
    "    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], \n",
    "                                  scores[:,1]+scores[:,2], alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "def write_answer_1(auc_1, auc_2):\n",
    "    auc = (auc_1 + auc_2)/2\n",
    "    with open(\"preprocessing_lr_answer1.txt\", \"w\") as fout:\n",
    "        fout.write(str(auc))\n",
    "        \n",
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "cv = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_real_zeros_oh = np.hstack((X_train_real_zeros, X_train_cat_oh))\n",
    "X_train_real_means_oh = np.hstack((X_train_real_mean, X_train_cat_oh))\n",
    "X_test_real_zeros_oh = np.hstack((X_test_real_zeros, X_test_cat_oh))\n",
    "X_test_real_means_oh = np.hstack((X_test_real_mean, X_test_cat_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "clf_zeros = GridSearchCV(estimator, param_grid, cv = 3)\n",
    "clf_zeros.fit(X_train_real_zeros_oh, y_train)\n",
    "clf_zeros.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_scores(clf_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044703279461389"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_zeros = clf_zeros.predict_proba(X_test_real_zeros_oh)[:, 1]\n",
    "roc_auc_zeros = roc_auc_score(y_test, y_zeros)\n",
    "roc_auc_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7b447e46926f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_mean' is not defined"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression()\n",
    "clf_mean = GridSearchCV(estimator, param_grid, cv = 3)\n",
    "clf_mean.fit(X_train_mean, y_train)\n",
    "clf_mean.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(clf_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
